{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fb5de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['réalisation cinématographique et audiovisuelle', 'mathématiques', 'poissonnerie', 'philosophie, éthique et théologie', 'gestion en banque et assurance']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random \n",
    "random.seed(42)\n",
    "\n",
    "with open(\"templates/lettre_motiv_templates_echantillon_car.json\", encoding=\"utf-8\") as f:\n",
    "    templates = json.load(f)\n",
    "    \n",
    "#first_themes = list(templates.keys())[:20] \n",
    "\n",
    "# select manually 5 topics : 1 that doesn't seem to carry gender stereotypes, 2 stereotypically masc, 2 fem\n",
    "selected_topics = ['géographie', 'assistance informatique, maintenance de logiciels et réseaux', \n",
    "                  'construction, bâtiment et travaux publics', \n",
    "                  \"diététique\", \"coiffure\"]\n",
    "\n",
    "# select 5 others randomly\n",
    "remaining_topics = [top for top in list(templates.keys()) if top not in selected_topics]\n",
    "\n",
    "random_topics = random.sample(remaining_topics, 5)\n",
    "print(random_topics)\n",
    "\n",
    "# merge the 2 lists\n",
    "topics = random_topics+selected_topics\n",
    "\n",
    "# select 10 generations randomly per topic and create a csv with all these generations (10 topics*10 generation*6 models)\n",
    "LLM = [\"bloom-560m\",\"bloom-3b\",\"bloom-7b\",\"vigogne-2-7b\", \"gpt2-fr\", \"xglm-2.9B\"]\n",
    "df_total = []\n",
    "for model in LLM:\n",
    "    llm_path = f\"output/coverletter_sampling_{model}.csv\"\n",
    "    df = pd.read_csv(llm_path)\n",
    "    df_combined = df[df[\"Theme\"]==topics[0]].sample(10).reset_index()\n",
    "    for topic in topics[1:]:\n",
    "        df_new = df[df[\"Theme\"]==topic].sample(10).reset_index()\n",
    "        df_combined = pd.concat([df_combined,df_new])\n",
    "    df_combined['model'] = model\n",
    "    df_combined['label_fem'] = ''\n",
    "    df_combined['label_nofem'] = ''\n",
    "    df_combined['bad'] = False\n",
    "    df_total.append(df_combined)\n",
    "\n",
    "df_combined_total = pd.concat(df_total)\n",
    "df_combined_total.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_combined_total.to_csv(\"annotation_manuelle/golden_selection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241cc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['réalisation cinématographique et audiovisuelle', 'mathématiques', 'poissonnerie', 'philosophie, éthique et théologie', 'gestion en banque et assurance']\n",
      "           top_p      top_k         model            Theme  \\\n",
      "0     top_p:0.75  top_k:100  vigogne-2-7b  psychopédagogie   \n",
      "1     top_p:0.75  top_k:100  vigogne-2-7b  psychopédagogie   \n",
      "2     top_p:0.75  top_k:100  vigogne-2-7b  psychopédagogie   \n",
      "3     top_p:0.75  top_k:100  vigogne-2-7b  psychopédagogie   \n",
      "4     top_p:0.75  top_k:100  vigogne-2-7b  psychopédagogie   \n",
      "...          ...        ...           ...              ...   \n",
      "4987  top_p:0.95   top_k:10  vigogne-2-7b         stylisme   \n",
      "4988  top_p:0.95   top_k:10  vigogne-2-7b         stylisme   \n",
      "4989  top_p:0.95   top_k:10  vigogne-2-7b         stylisme   \n",
      "4990  top_p:0.95   top_k:10  vigogne-2-7b         stylisme   \n",
      "4991  top_p:0.95   top_k:10  vigogne-2-7b         stylisme   \n",
      "\n",
      "                                                 prompt  \\\n",
      "0     Je finis actuellement mes études de psychopéda...   \n",
      "1     Je finis actuellement mes études de psychopéda...   \n",
      "2     Je finis actuellement mes études de psychopéda...   \n",
      "3     En réponse à votre offre d'emploi, j'ai le pla...   \n",
      "4     En réponse à votre offre d'emploi, j'ai le pla...   \n",
      "...                                                 ...   \n",
      "4987  Je possède un diplôme de stylisme et je suis à...   \n",
      "4988  Je possède un diplôme de stylisme et je suis à...   \n",
      "4989  En réponse à votre offre d'emploi, j'ai le pla...   \n",
      "4990  En réponse à votre offre d'emploi, j'ai le pla...   \n",
      "4991  En réponse à votre offre d'emploi, j'ai le pla...   \n",
      "\n",
      "                                                 output  \n",
      "0     <s> Je finis actuellement mes études de psycho...  \n",
      "1     <s> Je finis actuellement mes études de psycho...  \n",
      "2     <s> Je finis actuellement mes études de psycho...  \n",
      "3     <s> En réponse à votre offre d'emploi, j'ai le...  \n",
      "4     <s> En réponse à votre offre d'emploi, j'ai le...  \n",
      "...                                                 ...  \n",
      "4987  <s> Je possède un diplôme de stylisme et je su...  \n",
      "4988  <s> Je possède un diplôme de stylisme et je su...  \n",
      "4989  <s> En réponse à votre offre d'emploi, j'ai le...  \n",
      "4990  <s> En réponse à votre offre d'emploi, j'ai le...  \n",
      "4991  <s> En réponse à votre offre d'emploi, j'ai le...  \n",
      "\n",
      "[4992 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random \n",
    "random.seed(42)\n",
    "\n",
    "with open(\"templates/lettre_motiv_templates_echantillon_car.json\", encoding=\"utf-8\") as f:\n",
    "    templates = json.load(f)\n",
    "    \n",
    "#first_themes = list(templates.keys())[:20] \n",
    "\n",
    "# select manually 5 topics : 1 that doesn't seem to carry gender stereotypes, 2 stereotypically masc, 2 fem\n",
    "selected_topics = ['géographie', 'assistance informatique, maintenance de logiciels et réseaux', \n",
    "                  'construction, bâtiment et travaux publics', \n",
    "                  \"diététique\", \"coiffure\"]\n",
    "\n",
    "# select 5 others randomly\n",
    "remaining_topics = [top for top in list(templates.keys()) if top not in selected_topics]\n",
    "\n",
    "random_topics = random.sample(remaining_topics, 5)\n",
    "print(random_topics)\n",
    "\n",
    "# merge the 2 lists\n",
    "topics = random_topics+selected_topics\n",
    "\n",
    "# select 10 generations randomly per topic and create a csv with all these generations (10 topics*10 generation*6 models)\n",
    "#LLM = [\"bloom-560m\",\"bloom-3b\",\"bloom-7b\",\"vigogne-2-7b\", \"gpt2-fr\", \"xglm-2.9B\"]\n",
    "LLM = [\"vigogne-2-7b\", \"gpt2-fr\", \"xglm-2.9B\"]\n",
    "df_total = []\n",
    "for model in LLM:\n",
    "    llm_path = f\"output/coverletter_sampling_{model}.csv\"\n",
    "    df = pd.read_csv(llm_path)\n",
    "    #df = df[len(df[\"output\"])>5] \n",
    "    #df = df[df['output'].str.contains(\"Je\")]\n",
    "    #print(df)\n",
    "    #break\n",
    "    \"\"\"df_combined = df[df[\"Theme\"]==topics[0]].sample(10).reset_index()\n",
    "    for topic in topics[1:]:\n",
    "        df_new = df[df[\"Theme\"]==topic].sample(10).reset_index()\n",
    "        df_combined = pd.concat([df_combined,df_new])\n",
    "    df_combined['model'] = model\n",
    "    df_combined['label_fem'] = ''\n",
    "    df_combined['label_nofem'] = ''\n",
    "    df_combined['bad'] = False\n",
    "    df_total.append(df_combined)\n",
    "\n",
    "df_combined_total = pd.concat(df_total)\n",
    "df_combined_total.drop('Unnamed: 0', axis=1, inplace=True)\"\"\"\n",
    "#df_combined_total.to_csv(\"annotation_manuelle/golden_selection_fin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f16c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplir automatiquement les annotations déjà existantes pour bloom-560m et bloom-3b\n",
    "df = pd.read_csv(\"annotation_manuelle/golden_selection.csv\")\n",
    "sub_df = df[df[\"model\"]==\"bloom-560m\"]\n",
    "sub_df = sub_df[sub_df[\"index\"]<501]\n",
    "df_bloom560 = pd.read_csv(\"annotation_manuelle/sampling_lm_manu_annotated_gender_bloom560m.csv\")\n",
    "# aussi ajouter colonne comments\n",
    "# prendre golden_gender_feminisation => label_fem ; golden_gender_nofem => label_nofem\n",
    "df['label_fem'] = sub_df['index'].map(df_bloom560.set_index('Unnamed: 0')['golden_gender_feminisation'])\n",
    "#df1['Weight'] = df1['ID'].map(df2.set_index('ID')['Value'])\n",
    "df['label_nofem'] = sub_df['index'].map(df_bloom560.set_index('Unnamed: 0')['golden_gender_nonfem'])\n",
    "df['quality'] = sub_df['index'].map(df_bloom560.set_index('Unnamed: 0')['comments'])\n",
    "df[df['index']<500]\n",
    "#df.to_csv(\"annotation_manuelle/golden_selection.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
